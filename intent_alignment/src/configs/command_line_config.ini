[DEFAULT]
agent_type = command_line
suite = command_line
temperature = 0.7
# Simple agents integration
use_simple_agents = true

[simple_agents]
# Simple agents configuration (when use_simple_agents = true)
model_provider = ollama
model_name = llama3.3:70b
base_url = http://10.15.30.24:11434/v1
api_key = ollama

tool_response_model_provider = ollama
tool_response_model_name = llama3.3:70b
tool_response_base_url = http://10.15.30.24:11434/v1
tool_response_api_key = ollama

[models]
# Attack evaluation
attack_eval_provider = ollama
attack_eval_model = gpt-oss:120b
attack_eval_base_url = http://10.15.30.24:11434/v1
attack_eval_api_key = ollama

# Attack orchestrator model for payload generation
attack_gen_provider = ollama
attack_gen_model = huihui_ai/gpt-oss-abliterated:120b
attack_gen_base_url = http://10.15.30.24:11434/v1
attack_gen_api_key = ollama

# To use OpenAI, DeepInfra, or NVIDIA:
# 1. Set environment variable (OPENAI_API_KEY, DEEPINFRA_API_KEY, or NVIDIA_API_KEY)
# 2. Change provider above (e.g., attack_gen_provider = nvidia)
# 3. Update model name for that provider
# Note: base_url is NOT needed - defined as global constants in model_loader.py 

[pair_attack]
# PAIR attack campaign configuration
max_iterations = 50
storage_dir = attack_records_new

[paths]
# Framework and attack data paths
framework_data_path = /home/rohseque/Bounded-LLM-Agents/red_agent/attack_frameworks/email/email_attack_framework.csv
attack_storage_path = data/new_attack_records.json
# Policy path
# policy_path = policy_generator/output/policy.json

[ollama]
# Ollama server configuration
base_url = 10.15.30.23:11434